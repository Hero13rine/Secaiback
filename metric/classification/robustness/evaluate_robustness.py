import numpy as np
import torch
from torchvision import transforms
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import os

from attack import AttackFactory
from utils.SecAISender import ResultSender
from utils.visualize import denormalize  # ä»ä¿ç•™åŸåå½’ä¸€åŒ–å‡½æ•°

from method.corruptions import (
    gaussian_noise, shot_noise, impulse_noise, speckle_noise,
    gaussian_blur, glass_blur, defocus_blur, motion_blur, zoom_blur,
    fog, frost, snow, spatter, contrast, brightness, saturate,
    jpeg_compression, pixelate, elastic_transform
)

# ============================================================
# ğŸ”§ æ–°å¢ï¼šè‡ªåŠ¨æ£€æµ‹å›¾åƒå€¼åŸŸå¹¶æ­£ç¡®åå½’ä¸€åŒ–æ˜¾ç¤º
# ============================================================
def safe_to_display(img):
    """æ™ºèƒ½æ£€æµ‹å›¾åƒå€¼åŸŸå’Œæ ¼å¼ï¼Œè‡ªåŠ¨è½¬æ¢ä¸º0-1çš„HWCæ ¼å¼ä»¥ä¾¿imshow"""
    if isinstance(img, torch.Tensor):
        img = img.detach().cpu().numpy()
    if img.ndim == 3 and img.shape[0] == 3:
        img = np.transpose(img, (1, 2, 0))  # CHW -> HWC

    # è‡ªåŠ¨æ£€æµ‹å€¼åŸŸ
    if img.max() <= 1.0 and img.min() >= 0.0:
        # å·²ç»æ˜¯ [0,1]
        return np.clip(img, 0, 1)
    elif img.max() > 10:
        # å¯èƒ½æ˜¯ [0,255]
        return np.clip(img / 255.0, 0, 1)
    elif img.min() < 0:
        # å¯èƒ½æ˜¯æ ‡å‡†åŒ–åçš„ [-2,2]
        try:
            img = denormalize(img)
            return np.clip(img, 0, 1)
        except Exception:
            return np.clip((img + 1) / 2, 0, 1)
    else:
        return np.clip(img, 0, 1)

# ============================================================
# Softmax å‡½æ•°
# ============================================================
def softmax(x):
    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
    return exp_x / np.sum(exp_x, axis=1, keepdims=True)

# ============================================================
# ä¸»å‡½æ•°å…¥å£ï¼šé²æ£’æ€§è¯„æµ‹
# ============================================================
def evaluation_robustness(test_loader, estimator, metrics):
    ResultSender.send_log("è¿›åº¦", "é²æ£’æ€§è¯„æµ‹å¼€å§‹")
    print("é²æ£’æ€§è¯„æµ‹å¼€å§‹")
    try:
        metrics_adv = metrics["adversarial"]
        if len(metrics_adv) > 0:
            evaluate_robustness_adv_all(test_loader, estimator, metrics_adv)
        metrics_cor = metrics["corruption"]
        if len(metrics_cor) > 0:
            evaluate_robustness_corruptions(test_loader, estimator, metrics_cor)
        ResultSender.send_status("æˆåŠŸ")
        ResultSender.send_log("è¿›åº¦", "è¯„æµ‹ç»“æœå·²å†™å›æ•°æ®åº“")
    except Exception as e:
        ResultSender.send_status("å¤±è´¥")
        ResultSender.send_log("é”™è¯¯", str(e))
        raise

# ============================================================
# ç»Ÿä¸€é¢„æµ‹å‡½æ•°ï¼ˆå…¼å®¹4D/5Dï¼‰
# ============================================================
def process_predictions(images_np, estimator):
    if len(images_np.shape) == 5:
        bs, ncrops, c, h, w = images_np.shape
        images_flat = images_np.reshape(-1, c, h, w)
        outputs = estimator.predict(images_flat)
        outputs_avg = outputs.reshape(bs, ncrops, -1).mean(axis=1)
        return outputs_avg
    elif len(images_np.shape) == 4:
        return estimator.predict(images_np)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç»´åº¦: {images_np.shape}")

# ============================================================
# ä¿å­˜å¯¹æŠ—æ ·æœ¬å¯¹æ¯”å›¾
# ============================================================
def save_comparison_images(clean_img, adv_img, true_label, clean_pred, adv_pred, index, save_dir, eps=None):
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))

    clean_img_vis = safe_to_display(clean_img)
    adv_img_vis = safe_to_display(adv_img)

    axes[0].imshow(clean_img_vis)
    axes[0].set_title(f"Clean Image\nTrue: {true_label}, Pred: {clean_pred}")
    axes[0].axis('off')

    axes[1].imshow(adv_img_vis)
    axes[1].set_title(f"Adversarial Image\nTrue: {true_label}, Pred: {adv_pred}")
    axes[1].axis('off')

    plt.tight_layout()
    filename = f"comparison_{index}.png"
    if eps is not None:
        filename = f"fgsm_eps_{str(eps).replace('.', '_')}_comparison_{index}.png"
    plt.savefig(os.path.join(save_dir, filename))
    plt.close()
    return filename

# ============================================================
# å¯¹æŠ—æ”»å‡»è¯„æµ‹æ ¸å¿ƒå‡½æ•°
# ============================================================
def evaluate_robustness_adv(test_loader, estimator, attack, save_images=False, save_dir="adv_examples", eps=None):
    total_uncorrect_adv = 0
    total_samples = 0
    successful_attack_confidences = []
    acac_confidences = []

    saved_images_count = 0
    max_saved_images = 5

    for x_batch, y_batch in test_loader:
        x_batch_np = x_batch.numpy().astype(np.float32)
        y_batch_np = y_batch.numpy()
        bs = y_batch_np.shape[0]

        # ç”Ÿæˆå¯¹æŠ—æ ·æœ¬
        if len(x_batch_np.shape) == 5:
            bs_adv, ncrops_adv, c_adv, h_adv, w_adv = x_batch_np.shape
            x_flat = x_batch_np.reshape(-1, c_adv, h_adv, w_adv)
            x_adv_flat = attack.generate(x_flat)
            x_adv_np = x_adv_flat.reshape(bs_adv, ncrops_adv, c_adv, h_adv, w_adv)
        else:
            x_adv_np = attack.generate(x_batch_np)

        # å¯¹æŠ—æ ·æœ¬é¢„æµ‹
        pred_adv = process_predictions(x_adv_np, estimator)
        pred_adv_probs = softmax(pred_adv)
        total_uncorrect_adv += np.sum(np.argmax(pred_adv_probs, axis=1) != y_batch_np)

        # åŸå§‹æ ·æœ¬é¢„æµ‹
        pred_clean = process_predictions(x_batch_np, estimator)
        pred_clean_probs = softmax(pred_clean)

        # ç»Ÿè®¡æ”»å‡»æˆåŠŸæ ·æœ¬ç½®ä¿¡åº¦
        attack_success = np.argmax(pred_adv_probs, axis=1) != y_batch_np
        for i in range(bs):
            if attack_success[i]:
                true_class_confidence = pred_adv_probs[i][y_batch_np[i]]
                successful_attack_confidences.append(true_class_confidence)
                misclassified_confidence = np.max(pred_adv_probs[i])
                acac_confidences.append(misclassified_confidence)

            if save_images and saved_images_count < max_saved_images:
                clean_pred_label = np.argmax(pred_clean_probs[i])
                adv_pred_label = np.argmax(pred_adv_probs[i])
                if clean_pred_label == y_batch_np[i] and attack_success[i]:
                    clean_img = x_batch_np[i][0] if len(x_batch_np.shape) == 5 else x_batch_np[i]
                    adv_img = x_adv_np[i][0] if len(x_adv_np.shape) == 5 else x_adv_np[i]
                    filename = save_comparison_images(
                        clean_img, adv_img,
                        y_batch_np[i], clean_pred_label, adv_pred_label,
                        saved_images_count, save_dir, eps
                    )
                    saved_images_count += 1

        total_samples += bs

    adverr = total_uncorrect_adv / total_samples
    advacc = 1 - adverr
    print(f"Adversarial dataset accuracy: {advacc:.2%}")
    print(f"Adversarial dataset error: {adverr:.2%}")

    actc = np.mean(successful_attack_confidences) if successful_attack_confidences else None
    acac = np.mean(acac_confidences) if acac_confidences else None
    if actc is not None:
        print(f"actc: {actc:.4f}")
    else:
        print("No successful attacks found. actc cannot be calculated.")
    if acac is not None:
        print(f"acac: {acac:.4f}")
    else:
        print("No successful attacks found. acac cannot be calculated.")

    return adverr, advacc, actc, acac

# ============================================================
# è§£ææ”»å‡»å‚æ•°
# ============================================================
def parse_attack_method(attack_str, eps):
    return {"method": attack_str, "parameters": {"eps": eps}}

# ============================================================
# ä¿å­˜æ‰°åŠ¨å¯¹æ¯”å›¾
# ============================================================
def save_corruption_comparison(clean_img, corrupted_img, true_label, clean_pred, corrupted_pred, index, save_dir,
                               corruption_name, severity):
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))

    clean_img_display = safe_to_display(clean_img)
    corrupted_img_display = safe_to_display(corrupted_img)

    axes[0].imshow(clean_img_display)
    axes[0].set_title(f"Clean\nTrue: {true_label}, Pred: {clean_pred}")
    axes[0].axis('off')

    axes[1].imshow(corrupted_img_display)
    axes[1].set_title(f"{corruption_name}\nSeverity={severity}\nTrue: {true_label}, Pred: {corrupted_pred}")
    axes[1].axis('off')

    plt.tight_layout()
    filename = f"{corruption_name}_severity_{severity}_comparison_{index}.png"
    plt.savefig(os.path.join(save_dir, filename))
    plt.close()
    return filename

def evaluate_robustness_adv_all(test_loader, estimator, metrics):
    ResultSender.send_log("è¿›åº¦", "å¯¹æŠ—æ”»å‡»è¯„æµ‹å¼€å§‹")
    attack_method = ["fgsm"]
    eps_list = [round(eps, 1) for eps in np.arange(0.0, 1.1, 0.1)]
    eps_results = {}
    selected_eps_for_saving = [0.3, 0.6] if len(eps_list) > 1 else [eps_list[0]]

    for attack_name in attack_method:
        for eps in eps_list:
            print(f"\nEvaluating {attack_name} with eps={eps}")
            attack_config = parse_attack_method(attack_name, eps)
            attack = AttackFactory.create(
                estimator=estimator.get_core(),
                config=attack_config
            )
            # åªåœ¨é€‰å®šçš„epså€¼æ—¶ä¿å­˜å›¾åƒ
            save_images = eps in selected_eps_for_saving
            # æ„å»ºç›´æ¥ä¿å­˜åˆ°ç»“æœç›®å½•çš„è·¯å¾„
            evaluateMetric = os.getenv("evaluateDimension")
            save_dir = None
            if save_images and evaluateMetric:
                save_dir = os.path.join("..", "evaluationData", evaluateMetric, "output")
                os.makedirs(save_dir, exist_ok=True)
            elif save_images:
                save_dir = f"adv_examples_{attack_name}_{str(eps).replace('.', '_')}"
                os.makedirs(save_dir, exist_ok=True)

            if save_dir:
                adverr, advacc, actc, acac = evaluate_robustness_adv(test_loader, estimator, attack,
                                                                     save_images=save_images,
                                                                     save_dir=save_dir, eps=eps)
            else:
                adverr, advacc, actc, acac = evaluate_robustness_adv(test_loader, estimator, attack,
                                                                     save_images=save_images)

            eps_results[eps] = {
                'adverr': adverr,
                'advacc': advacc,
                'actc': actc,
                'acac': acac
            }

            # å‘é€æŒ‡æ ‡ç»“æœ
            for metric in metrics:
                value = eps_results[eps][metric]
                eps_str = str(eps).replace('.', '_')
                key = f"{metric}_{eps_str}"
                if value is not None:
                    ResultSender.send_result(key, f"{value:.4f}")
                else:
                    ResultSender.send_result(key, "None")

        try:
            # è·å–ç¯å¢ƒå˜é‡
            evaluateMetric = os.getenv("evaluateDimension")
            resultPath = os.getenv("resultPath")

            if evaluateMetric and resultPath and selected_eps_for_saving:
                for eps in selected_eps_for_saving:
                    eps_str = str(eps).replace('.', '_')
                    # ç›´æ¥åœ¨ç»“æœç›®å½•ä¸­æŸ¥æ‰¾å›¾åƒ
                    target_dir_rel = os.path.join("..", "evaluationData", evaluateMetric, "output")
                    target_dir_abs = os.path.join(resultPath, evaluateMetric, "output")

                    # æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨
                    target_img_name = f"fgsm_eps_{eps_str}_comparison_0.png"
                    target_img_path_rel = os.path.join(target_dir_rel, target_img_name)
                    target_img_path_abs = os.path.join(target_dir_abs, target_img_name)

                    print(f"æ£€æŸ¥å¯¹æŠ—æ”»å‡»å›¾ç‰‡è·¯å¾„: {target_img_path_rel}")
                    print(f"æ£€æŸ¥å¯¹æŠ—æ”»å‡»å›¾ç‰‡ç»å¯¹è·¯å¾„: {target_img_path_abs}")

                    if os.path.exists(target_img_path_rel):
                        # é€šè¿‡ResultSenderå‘é€è·¯å¾„
                        ResultSender.send_result(f"fgsm_eps_{eps_str}_comparison_0_path", target_img_path_abs)

                        # æ‰“å°ä¿å­˜è·¯å¾„
                        print(f"å¯¹æŠ—æ”»å‡»å¯¹æ¯”å›¾å·²ä¿å­˜: {target_img_path_abs}")
                    else:
                        print(f"å¯¹æŠ—æ”»å‡»å¯¹æ¯”å›¾ä¸å­˜åœ¨: {target_img_path_rel}")
            else:
                print("ç¯å¢ƒå˜é‡ evaluateDimension æˆ– resultPath æœªè®¾ç½®ï¼Œè·³è¿‡å‘é€å¯¹æ¯”å›¾è·¯å¾„")
        except Exception as e:
            print(f"å‘é€å¯¹æŠ—æ”»å‡»å¯¹æ¯”å›¾è·¯å¾„æ—¶å‡ºé”™: {e}")

    # å‘é€å¹³å‡æŒ‡æ ‡
    for metric in metrics:
        valid_values = [results[metric] for eps, results in eps_results.items() if results[metric] is not None]
        if valid_values:
            avg = sum(valid_values) / len(valid_values)
            print(f"Average {metric} across all eps: {avg:.4f}")
            ResultSender.send_result(f"{metric}_avg", f"{avg:.4f}")
        else:
            print(f"No valid values for {metric} across all eps")
            ResultSender.send_result(f"{metric}_avg", "None")

    return eps_results, avg  # ä¿®æ­£è¿”å›å€¼ï¼ˆåŸavg_resultsæœªå®šä¹‰ï¼Œç›´æ¥è¿”å›avgï¼‰

def evaluate_clean(test_loader, estimator):
    total_incorrect_clean = 0  # ä¿®æ­£å˜é‡åï¼ˆåŸtotal_correct_cleanè¯­ä¹‰çŸ›ç›¾ï¼‰
    total_samples = 0

    for x_batch, y_batch in test_loader:
        x_batch_np = x_batch.numpy().astype(np.float32)
        y_batch_np = y_batch.numpy()
        bs = y_batch_np.shape[0]

        # åŸå§‹é¢„æµ‹
        pred_clean = process_predictions(x_batch_np, estimator)
        pred_clean_probs = softmax(pred_clean)
        # ç»Ÿè®¡é¢„æµ‹é”™è¯¯çš„æ ·æœ¬æ•°ï¼ˆåŸé€»è¾‘æ­£ç¡®ï¼Œä¿®æ­£å˜é‡åä½¿å…¶è¯­ä¹‰æ¸…æ™°ï¼‰
        total_incorrect_clean += np.sum(np.argmax(pred_clean_probs, axis=1) != y_batch_np)
        total_samples += bs

    err_clean = 100 * total_incorrect_clean / total_samples
    print(f"asr_clean (full test set): {err_clean:.2f}%")
    return err_clean

def get_original_image(images, idx):
    """ä»4ç»´æˆ–5ç»´å¼ é‡ä¸­æå–åŸå§‹å›¾åƒï¼ˆç”¨äºå¯è§†åŒ–ï¼‰"""
    if len(images.shape) == 4:
        # (bs, c, h, w) â†’ å–å•ä¸ªæ ·æœ¬å¹¶è½¬HWCæ ¼å¼ï¼ˆ0-255ï¼‰
        return images[idx].permute(1, 2, 0).numpy() * 255
    elif len(images.shape) == 5:
        # (bs, ncrops, c, h, w) â†’ å–ç¬¬ä¸€ä¸ªè£å‰ªå›¾å¹¶è½¬HWCæ ¼å¼ï¼ˆ0-255ï¼‰
        return images[idx, 0].permute(1, 2, 0).numpy() * 255
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å›¾åƒç»´åº¦: {images.shape}")

def evaluate_robustness_corruptions(test_loader, estimator, metrics):
    ResultSender.send_log("è¿›åº¦", "æ‰°åŠ¨æ”»å‡»è¯„æµ‹å¼€å§‹")
    # å®šä¹‰æ‰°åŠ¨æ–¹æ³•ï¼ˆå¯æ ¹æ®éœ€è¦è§£é™¤æ³¨é‡Šæ‰©å±•ï¼‰
    corruption_functions = [
        gaussian_noise,
        # shot_noise, impulse_noise, speckle_noise,
        # gaussian_blur, glass_blur, defocus_blur, motion_blur, zoom_blur,
        # fog, frost, snow, spatter, contrast, brightness, saturate,
        # jpeg_compression, pixelate, elastic_transform
    ]
    severity_levels = [1, 2, 3, 4, 5]
    asr_total = 0
    selected_severity_for_saving = [2, 4] if len(severity_levels) > 1 else [severity_levels[0]]

    for corruption_function in corruption_functions:
        corruption_name = corruption_function.__name__
        for severity in severity_levels:
            total_samples = 0
            incorrect_count = 0
            save_dir = None
            should_save_images = severity in selected_severity_for_saving

            # åˆ›å»ºä¿å­˜ç›®å½•
            if should_save_images:
                evaluateMetric = os.getenv("evaluateDimension")
                if evaluateMetric:
                    save_dir = os.path.join("..", "evaluationData", evaluateMetric, "output")
                    os.makedirs(save_dir, exist_ok=True)
                else:
                    save_dir = f"corruption_examples_{corruption_function.__name__}_{severity}"
                    os.makedirs(save_dir, exist_ok=True)

            saved_images_count = 0
            max_saved_images = 5

            with torch.no_grad():
                for data in test_loader:
                    images, labels = data
                    bs = images.shape[0]  # æ— è®º4ç»´è¿˜æ˜¯5ç»´ï¼Œæ‰¹æ¬¡å¤§å°éƒ½æ˜¯ç¬¬ä¸€ç»´

                    for i in range(bs):
                        # æå–åŸå§‹å›¾åƒï¼ˆç”¨äºæ‰°åŠ¨å’Œå¯è§†åŒ–ï¼‰
                        original_img = get_original_image(images, i).astype(np.uint8)
                        
                        # åº”ç”¨æ‰°åŠ¨ï¼ˆè¾“å…¥å¿…é¡»æ˜¯uint8æ ¼å¼çš„HWCå›¾åƒï¼‰
                        corrupted_img = corruption_function(original_img, severity=severity)
                        
                        # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼ï¼šHWC â†’ CHWï¼Œ0-1å½’ä¸€åŒ–ï¼Œæ·»åŠ æ‰¹æ¬¡ç»´åº¦
                        if isinstance(corrupted_img, np.ndarray):
                            # å¤„ç†numpyæ•°ç»„æ ¼å¼
                            corrupted_tensor = torch.from_numpy(corrupted_img / 255.0).permute(2, 0, 1).float()
                        else:
                            # å¤„ç†PILå›¾åƒæ ¼å¼
                            corrupted_tensor = transforms.ToTensor()(corrupted_img)
                        
                        # æ ¹æ®è¾“å…¥æ•°æ®ç±»å‹ç”Ÿæˆå¯¹åº”æ ¼å¼çš„æ‰°åŠ¨æ•°æ®
                        if len(images.shape) == 5:
                            # 5ç»´æ•°æ®ï¼šç”Ÿæˆ10æŠ˜è£å‰ªï¼Œä¿æŒæ ¼å¼ä¸º(1, 10, c, h, w)
                            ncrops = images.shape[1]
                            # TenCropè¿”å›tupleï¼Œéœ€è½¬æ¢ä¸ºtensorå¹¶æ·»åŠ æ‰¹æ¬¡ç»´åº¦
                            corrupted_crops = transforms.TenCrop(size=original_img.shape[:2])(corrupted_tensor)
                            corrupted_crops = torch.stack(corrupted_crops).unsqueeze(0)  # (1, 10, c, h, w)
                            model_input = corrupted_crops.numpy()
                        else:
                            # 4ç»´æ•°æ®ï¼šä¿æŒæ ¼å¼ä¸º(1, c, h, w)
                            model_input = corrupted_tensor.unsqueeze(0).numpy()
                        
                        # æ¨¡å‹é¢„æµ‹
                        pred = process_predictions(model_input, estimator)
                        pred_label = np.argmax(pred, axis=1)[0]
                        true_label = labels[i].item()

                        # ç»Ÿè®¡é”™è¯¯æ•°
                        if pred_label != true_label:
                            incorrect_count += 1
                        total_samples += 1

                        # ä¿å­˜å¯¹æ¯”å›¾åƒï¼ˆä»…å½“åŸå§‹é¢„æµ‹æ­£ç¡®ä¸”æ‰°åŠ¨åé¢„æµ‹é”™è¯¯æ—¶ï¼‰
                        if should_save_images and saved_images_count < max_saved_images:
                            # åŸå§‹å›¾åƒçš„é¢„æµ‹ï¼ˆä½¿ç”¨å®Œæ•´è¾“å…¥æ ¼å¼ï¼‰
                            original_input = images[i:i+1].numpy()  # ä¿æŒåŸå§‹ç»´åº¦ï¼ˆ1, ncrops, c, h, wï¼‰æˆ–ï¼ˆ1, c, h, wï¼‰
                            pred_clean = process_predictions(original_input, estimator)
                            clean_pred_label = np.argmax(pred_clean, axis=1)[0]
                            
                            if clean_pred_label == true_label and pred_label != true_label:
                                save_corruption_comparison(
                                    original_img,  # åŸå§‹å›¾åƒï¼ˆHWC, 0-255ï¼‰
                                    corrupted_img,  # æ‰°åŠ¨å›¾åƒï¼ˆHWC, 0-255ï¼‰
                                    true_label,
                                    clean_pred_label,
                                    pred_label,
                                    saved_images_count,
                                    save_dir,
                                    corruption_name,
                                    severity
                                )
                                saved_images_count += 1

            # è®¡ç®—ASRï¼ˆæ”»å‡»æˆåŠŸç‡=é”™è¯¯æ•°/æ€»æ ·æœ¬æ•°ï¼‰
            if total_samples > 0:
                asr = 100 * incorrect_count / total_samples
                asr_total += asr
                # æ—¥å¿—è¾“å‡º
                ResultSender.send_log("è¿›åº¦",
                                      f"UnCorrectNum of {corruption_name}_severity_{severity}: {incorrect_count}")
                ResultSender.send_log("è¿›åº¦",
                                      f"ASR of {corruption_name}_severity_{severity}: {asr:.2f}%")
                print(f"UnCorrectNum of {corruption_name}_severity_{severity}: {incorrect_count}")
                print(f"ASR of {corruption_name}_severity_{severity}: {asr:.2f}%")
                
                # å›¾åƒä¿å­˜æ—¥å¿—
                if should_save_images:
                    if saved_images_count > 0:
                        print(f"å·²ä¿å­˜ {saved_images_count} ç»„ {corruption_name}_severity_{severity} å¯¹æ¯”å›¾åˆ° {save_dir}")
                    else:
                        print(f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ ·æœ¬ï¼ˆåŸå§‹é¢„æµ‹æ­£ç¡®+æ‰°åŠ¨é¢„æµ‹é”™è¯¯ï¼‰ï¼Œæœªä¿å­˜ {corruption_name}_severity_{severity} å¯¹æ¯”å›¾")
            else:
                print(f"è­¦å‘Šï¼š{corruption_name}_severity_{severity} æœªå¤„ç†ä»»ä½•æ ·æœ¬")

        # å‘é€é€‰å®šseverityçº§åˆ«çš„å¯¹æ¯”å›¾è·¯å¾„
        try:
            # è·å–ç¯å¢ƒå˜é‡
            evaluateMetric = os.getenv("evaluateDimension")
            resultPath = os.getenv("resultPath")

            if evaluateMetric and resultPath and selected_severity_for_saving:
                for severity in selected_severity_for_saving:
                    # ç›´æ¥åœ¨ç»“æœç›®å½•ä¸­æŸ¥æ‰¾å›¾åƒ
                    target_dir_rel = os.path.join("..", "evaluationData", evaluateMetric, "output")
                    target_dir_abs = os.path.join(resultPath, evaluateMetric, "output")

                    # æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨
                    target_img_name = f"{corruption_function.__name__}_severity_{severity}_comparison_0.png"
                    target_img_path_rel = os.path.join(target_dir_rel, target_img_name)
                    target_img_path_abs = os.path.join(target_dir_abs, target_img_name)

                    print(f"æ£€æŸ¥æ‰°åŠ¨æ”»å‡»å›¾ç‰‡è·¯å¾„: {target_img_path_rel}")
                    print(f"æ£€æŸ¥æ‰°åŠ¨æ”»å‡»å›¾ç‰‡ç»å¯¹è·¯å¾„: {target_img_path_abs}")

                    if os.path.exists(target_img_path_rel):
                        # é€šè¿‡ResultSenderå‘é€è·¯å¾„
                        ResultSender.send_result(
                            f"{corruption_function.__name__}_severity_{severity}_comparison_0_path",
                            target_img_path_abs)

                        # æ‰“å°ä¿å­˜è·¯å¾„
                        print(f"æ‰°åŠ¨æ”»å‡»å¯¹æ¯”å›¾å·²ä¿å­˜: {target_img_path_abs}")
                    else:
                        print(f"æ‰°åŠ¨æ”»å‡»å¯¹æ¯”å›¾ä¸å­˜åœ¨: {target_img_path_rel}")
            else:
                print("ç¯å¢ƒå˜é‡ evaluateDimension æˆ– resultPath æœªè®¾ç½®ï¼Œè·³è¿‡å‘é€å¯¹æ¯”å›¾è·¯å¾„")
        except Exception as e:
            print(f"å‘é€æ‰°åŠ¨æ”»å‡»å¯¹æ¯”å›¾è·¯å¾„æ—¶å‡ºé”™: {e}")

    # è®¡ç®—mCEï¼ˆå¹³å‡ corruption errorï¼‰
    num_corruptions = len(corruption_functions)
    num_severities = len(severity_levels)
    if num_corruptions > 0 and num_severities > 0:
        mCE = asr_total / (num_corruptions * num_severities)
        print(f"mCE (Average Corruption Error): {mCE:.2f}%")
        if "mCE" in metrics:
            ResultSender.send_result("mCE", f"{mCE / 100:.4f}")  # è½¬æ¢ä¸ºå°æ•°å½¢å¼

        # è®¡ç®—RmCEï¼ˆç›¸å¯¹ mCE = mCE - å¹²å‡€æ ·æœ¬é”™è¯¯ç‡ï¼‰
        if "RmCE" in metrics:
            err_clean = evaluate_clean(test_loader, estimator)
            RmCE = mCE - err_clean
            print(f"RmCE (Relative mCE): {RmCE:.2f}%")
            ResultSender.send_result("RmCE", f"{RmCE / 100:.4f}")  # è½¬æ¢ä¸ºå°æ•°å½¢å¼
    else:
        print("è­¦å‘Šï¼šæœªè®¡ç®—mCEï¼ˆæ— æ‰°åŠ¨æ–¹æ³•æˆ–severityçº§åˆ«ï¼‰")
        if "mCE" in metrics:
            ResultSender.send_result("mCE", "0.0000")
        if "RmCE" in metrics:
            ResultSender.send_result("RmCE", "0.0000")