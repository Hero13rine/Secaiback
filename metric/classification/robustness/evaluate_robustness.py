import numpy as np
import torch
from torchvision import transforms
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import os

from attack import AttackFactory
from utils.SecAISender import ResultSender
from utils.visualize import denormalize  # ä»ä¿ç•™åŸåå½’ä¸€åŒ–å‡½æ•°

from .corruptions import (
    gaussian_noise, shot_noise, impulse_noise, speckle_noise,
    gaussian_blur, glass_blur, defocus_blur, motion_blur, zoom_blur,
    fog, frost, snow, spatter, contrast, brightness, saturate,
    jpeg_compression, pixelate, elastic_transform
)

# ============================================================
# ğŸ”§ æ–°å¢ï¼šè‡ªåŠ¨æ£€æµ‹å›¾åƒå€¼åŸŸå¹¶æ­£ç¡®åå½’ä¸€åŒ–æ˜¾ç¤º
# ============================================================
def safe_to_display(img):
    """æ™ºèƒ½æ£€æµ‹å›¾åƒå€¼åŸŸå’Œæ ¼å¼ï¼Œè‡ªåŠ¨è½¬æ¢ä¸º0-1çš„HWCæ ¼å¼ä»¥ä¾¿imshow"""
    if isinstance(img, torch.Tensor):
        img = img.detach().cpu().numpy()
    if img.ndim == 3 and img.shape[0] == 3:
        img = np.transpose(img, (1, 2, 0))  # CHW -> HWC
    elif img.ndim == 2:
        # ç°åº¦å›¾åƒï¼ˆHWCå•é€šé“ï¼‰
        pass

    # è‡ªåŠ¨æ£€æµ‹å€¼åŸŸ
    if img.max() <= 1.0 and img.min() >= 0.0:
        # å·²ç»æ˜¯ [0,1]
        return np.clip(img, 0, 1)
    elif img.max() > 10:
        # å¯èƒ½æ˜¯ [0,255]
        return np.clip(img / 255.0, 0, 1)
    elif img.min() < 0:
        # å¯èƒ½æ˜¯æ ‡å‡†åŒ–åçš„ [-2,2]
        try:
            img = denormalize(img)
            return np.clip(img, 0, 1)
        except Exception:
            return np.clip((img + 1) / 2, 0, 1)
    else:
        return np.clip(img, 0, 1)

# ============================================================
# Softmax å‡½æ•°
# ============================================================
def softmax(x):
    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
    return exp_x / np.sum(exp_x, axis=1, keepdims=True)

# ============================================================
# ä¸»å‡½æ•°å…¥å£ï¼šé²æ£’æ€§è¯„æµ‹
# ============================================================
def evaluation_robustness(test_loader, estimator, metrics):
    ResultSender.send_log("è¿›åº¦", "é²æ£’æ€§è¯„æµ‹å¼€å§‹")
    print("é²æ£’æ€§è¯„æµ‹å¼€å§‹")
    try:
        metrics_adv = metrics["adversarial"]
        if len(metrics_adv) > 0:
            evaluate_robustness_adv_all(test_loader, estimator, metrics_adv)
        metrics_cor = metrics["corruption"]
        if len(metrics_cor) > 0:
            evaluate_robustness_corruptions(test_loader, estimator, metrics_cor)
        ResultSender.send_status("æˆåŠŸ")
        ResultSender.send_log("è¿›åº¦", "è¯„æµ‹ç»“æœå·²å†™å›æ•°æ®åº“")
    except Exception as e:
        ResultSender.send_status("å¤±è´¥")
        ResultSender.send_log("é”™è¯¯", str(e))
        raise

# ============================================================
# ç»Ÿä¸€é¢„æµ‹å‡½æ•°ï¼ˆå…¼å®¹4D/5Dï¼‰
# ============================================================
def process_predictions(images_np, estimator):
    if len(images_np.shape) == 5:
        bs, ncrops, c, h, w = images_np.shape
        images_flat = images_np.reshape(-1, c, h, w)
        outputs = estimator.predict(images_flat)
        outputs_avg = outputs.reshape(bs, ncrops, -1).mean(axis=1)
        return outputs_avg
    elif len(images_np.shape) == 4:
        return estimator.predict(images_np)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç»´åº¦: {images_np.shape}")

# ============================================================
# ä¿å­˜å¯¹æŠ—æ ·æœ¬å¯¹æ¯”å›¾
# ============================================================
def save_comparison_images(clean_img, adv_img, true_label, clean_pred, adv_pred, index, save_dir, eps=None):
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))

    clean_img_vis = safe_to_display(clean_img)
    adv_img_vis = safe_to_display(adv_img)

    # è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦ä¸ºç°åº¦å›¾ï¼ˆå•é€šé“æˆ–ä¸‰é€šé“æ•°å€¼ä¸€è‡´ï¼‰
    is_clean_gray = clean_img_vis.ndim == 2 or (clean_img_vis.ndim == 3 and np.allclose(clean_img_vis[..., 0], clean_img_vis[..., 1]) and np.allclose(clean_img_vis[..., 0], clean_img_vis[..., 2]))
    is_adv_gray = adv_img_vis.ndim == 2 or (adv_img_vis.ndim == 3 and np.allclose(adv_img_vis[..., 0], adv_img_vis[..., 1]) and np.allclose(adv_img_vis[..., 0], adv_img_vis[..., 2]))

    axes[0].imshow(clean_img_vis, cmap='gray' if is_clean_gray else None)
    axes[0].set_title(f"Clean Image\nTrue: {true_label}, Pred: {clean_pred}")
    axes[0].axis('off')

    axes[1].imshow(adv_img_vis, cmap='gray' if is_adv_gray else None)
    axes[1].set_title(f"Adversarial Image\nTrue: {true_label}, Pred: {adv_pred}")
    axes[1].axis('off')

    plt.tight_layout()
    filename = f"comparison_{index}.png"
    if eps is not None:
        filename = f"fgsm_eps_{str(eps).replace('.', '_')}_comparison_{index}.png"
    plt.savefig(os.path.join(save_dir, filename))
    plt.close()
    return filename

# ============================================================
# å¯¹æŠ—æ”»å‡»è¯„æµ‹æ ¸å¿ƒå‡½æ•°
# ============================================================
def evaluate_robustness_adv(test_loader, estimator, attack, save_images=False, save_dir="adv_examples", eps=None):
    total_uncorrect_adv = 0
    total_samples = 0
    successful_attack_confidences = []
    acac_confidences = []

    saved_images_count = 0
    max_saved_images = 5

    for x_batch, y_batch in test_loader:
        x_batch_np = x_batch.numpy().astype(np.float32)
        y_batch_np = y_batch.numpy()
        bs = y_batch_np.shape[0]

        # ç”Ÿæˆå¯¹æŠ—æ ·æœ¬
        if len(x_batch_np.shape) == 5:
            bs_adv, ncrops_adv, c_adv, h_adv, w_adv = x_batch_np.shape
            x_flat = x_batch_np.reshape(-1, c_adv, h_adv, w_adv)
            x_adv_flat = attack.generate(x_flat)
            x_adv_np = x_adv_flat.reshape(bs_adv, ncrops_adv, c_adv, h_adv, w_adv)
        else:
            x_adv_np = attack.generate(x_batch_np)

        # å¯¹æŠ—æ ·æœ¬é¢„æµ‹
        pred_adv = process_predictions(x_adv_np, estimator)
        pred_adv_probs = softmax(pred_adv)
        total_uncorrect_adv += np.sum(np.argmax(pred_adv_probs, axis=1) != y_batch_np)

        # åŸå§‹æ ·æœ¬é¢„æµ‹
        pred_clean = process_predictions(x_batch_np, estimator)
        pred_clean_probs = softmax(pred_clean)

        # ç»Ÿè®¡æ”»å‡»æˆåŠŸæ ·æœ¬ç½®ä¿¡åº¦
        attack_success = np.argmax(pred_adv_probs, axis=1) != y_batch_np
        for i in range(bs):
            if attack_success[i]:
                true_class_confidence = pred_adv_probs[i][y_batch_np[i]]
                successful_attack_confidences.append(true_class_confidence)
                misclassified_confidence = np.max(pred_adv_probs[i])
                acac_confidences.append(misclassified_confidence)

            if save_images and saved_images_count < max_saved_images:
                clean_pred_label = np.argmax(pred_clean_probs[i])
                adv_pred_label = np.argmax(pred_adv_probs[i])
                if clean_pred_label == y_batch_np[i] and attack_success[i]:
                    # å›ºå®šå–ç¬¬ä¸€ä¸ªè£å‰ªå›¾ï¼ˆcrop_idx=0ï¼‰
                    clean_img = x_batch_np[i][0] if len(x_batch_np.shape) == 5 else x_batch_np[i]
                    adv_img = x_adv_np[i][0] if len(x_adv_np.shape) == 5 else x_adv_np[i]
                    filename = save_comparison_images(
                        clean_img, adv_img,
                        y_batch_np[i], clean_pred_label, adv_pred_label,
                        saved_images_count, save_dir, eps
                    )
                    saved_images_count += 1

        total_samples += bs

    adverr = total_uncorrect_adv / total_samples
    advacc = 1 - adverr
    print(f"Adversarial dataset accuracy: {advacc:.2%}")
    print(f"Adversarial dataset error: {adverr:.2%}")

    actc = np.mean(successful_attack_confidences) if successful_attack_confidences else None
    acac = np.mean(acac_confidences) if acac_confidences else None
    if actc is not None:
        print(f"actc: {actc:.4f}")
    else:
        print("No successful attacks found. actc cannot be calculated.")
    if acac is not None:
        print(f"acac: {acac:.4f}")
    else:
        print("No successful attacks found. acac cannot be calculated.")

    return adverr, advacc, actc, acac

# ============================================================
# è§£ææ”»å‡»å‚æ•°
# ============================================================
def parse_attack_method(attack_str, eps):
    return {
        "method": attack_str,
        "parameters": {
            "eps": eps,
            "step_size": 0.005
        }
    }

# ============================================================
# ä¿å­˜æ‰°åŠ¨å¯¹æ¯”å›¾
# ============================================================
def save_corruption_comparison(clean_img, corrupted_img, true_label, clean_pred, corrupted_pred, index, save_dir,
                               corruption_name, severity):
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))

    clean_img_display = safe_to_display(clean_img)
    corrupted_img_display = safe_to_display(corrupted_img)

    # è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦ä¸ºç°åº¦å›¾ï¼ˆå•é€šé“æˆ–ä¸‰é€šé“æ•°å€¼ä¸€è‡´ï¼‰
    is_clean_gray = clean_img_display.ndim == 2 or (clean_img_display.ndim == 3 and np.allclose(clean_img_display[..., 0], clean_img_display[..., 1]) and np.allclose(clean_img_display[..., 0], clean_img_display[..., 2]))
    is_corrupted_gray = corrupted_img_display.ndim == 2 or (corrupted_img_display.ndim == 3 and np.allclose(corrupted_img_display[..., 0], corrupted_img_display[..., 1]) and np.allclose(corrupted_img_display[..., 0], corrupted_img_display[..., 2]))

    axes[0].imshow(clean_img_display, cmap='gray' if is_clean_gray else None)
    axes[0].set_title(f"Clean\nTrue: {true_label}, Pred: {clean_pred}")
    axes[0].axis('off')

    axes[1].imshow(corrupted_img_display, cmap='gray' if is_corrupted_gray else None)
    axes[1].set_title(f"{corruption_name}\nSeverity={severity}\nTrue: {true_label}, Pred: {corrupted_pred}")
    axes[1].axis('off')

    plt.tight_layout()
    filename = f"{corruption_name}_severity_{severity}_comparison_{index}.png"
    plt.savefig(os.path.join(save_dir, filename))
    plt.close()
    return filename

def evaluate_robustness_adv_all(test_loader, estimator, metrics):
    ResultSender.send_log("è¿›åº¦", "å¯¹æŠ—æ”»å‡»è¯„æµ‹å¼€å§‹")
    attack_method = ["fgsm"]
    eps_list = [round(eps, 3) for eps in np.arange(0, 0.101, 0.001)]
    eps_results = {}
    selected_eps_for_saving = [0.003, 0.006] if len(eps_list) > 1 else [eps_list[0]]

    for attack_name in attack_method:
        for eps in eps_list:
            print(f"\nEvaluating {attack_name} with eps={eps}")
            attack_config = parse_attack_method(attack_name, eps)
            attack = AttackFactory.create(
                estimator=estimator.get_core(),
                config=attack_config
            )
            # åªåœ¨é€‰å®šçš„epså€¼æ—¶ä¿å­˜å›¾åƒ
            save_images = eps in selected_eps_for_saving
            # æ„å»ºç›´æ¥ä¿å­˜åˆ°ç»“æœç›®å½•çš„è·¯å¾„
            evaluateMetric = os.getenv("evaluateDimension")
            save_dir = None
            if save_images and evaluateMetric:
                save_dir = os.path.join("..", "evaluationData", evaluateMetric, "output")
                os.makedirs(save_dir, exist_ok=True)
            elif save_images:
                save_dir = f"adv_examples_{attack_name}_{str(eps).replace('.', '_')}"
                os.makedirs(save_dir, exist_ok=True)

            if save_dir:
                adverr, advacc, actc, acac = evaluate_robustness_adv(test_loader, estimator, attack,
                                                                     save_images=save_images,
                                                                     save_dir=save_dir, eps=eps)
            else:
                adverr, advacc, actc, acac = evaluate_robustness_adv(test_loader, estimator, attack,
                                                                     save_images=save_images)

            eps_results[eps] = {
                'adverr': adverr,
                'advacc': advacc,
                'actc': actc,
                'acac': acac
            }

            # å‘é€æŒ‡æ ‡ç»“æœ
            for metric in metrics:
                value = eps_results[eps][metric]
                eps_str = str(eps).replace('.', '_')
                key = f"{metric}_{eps_str}"
                if value is not None:
                    ResultSender.send_result(key, f"{value:.4f}")
                else:
                    ResultSender.send_result(key, "None")

        try:
            # è·å–ç¯å¢ƒå˜é‡
            evaluateMetric = os.getenv("evaluateDimension")
            resultPath = os.getenv("resultPath")

            if evaluateMetric and resultPath and selected_eps_for_saving:
                for eps in selected_eps_for_saving:
                    eps_str = str(eps).replace('.', '_')
                    # ç›´æ¥åœ¨ç»“æœç›®å½•ä¸­æŸ¥æ‰¾å›¾åƒ
                    target_dir_rel = os.path.join("..", "evaluationData", evaluateMetric, "output")
                    target_dir_abs = os.path.join(resultPath, evaluateMetric, "output")

                    # æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨
                    target_img_name = f"fgsm_eps_{eps_str}_comparison_0.png"
                    target_img_path_rel = os.path.join(target_dir_rel, target_img_name)
                    target_img_path_abs = os.path.join(target_dir_abs, target_img_name)

                    print(f"æ£€æŸ¥å¯¹æŠ—æ”»å‡»å›¾ç‰‡è·¯å¾„: {target_img_path_rel}")
                    print(f"æ£€æŸ¥å¯¹æŠ—æ”»å‡»å›¾ç‰‡ç»å¯¹è·¯å¾„: {target_img_path_abs}")

                    if os.path.exists(target_img_path_rel):
                        # é€šè¿‡ResultSenderå‘é€è·¯å¾„
                        ResultSender.send_result(f"fgsm_eps_{eps_str}_comparison_0_path", target_img_path_abs)

                        # æ‰“å°ä¿å­˜è·¯å¾„
                        print(f"å¯¹æŠ—æ”»å‡»å¯¹æ¯”å›¾å·²ä¿å­˜: {target_img_path_abs}")
                    else:
                        print(f"å¯¹æŠ—æ”»å‡»å¯¹æ¯”å›¾ä¸å­˜åœ¨: {target_img_path_rel}")
            else:
                print("ç¯å¢ƒå˜é‡ evaluateDimension æˆ– resultPath æœªè®¾ç½®ï¼Œè·³è¿‡å‘é€å¯¹æ¯”å›¾è·¯å¾„")
        except Exception as e:
            print(f"å‘é€å¯¹æŠ—æ”»å‡»å¯¹æ¯”å›¾è·¯å¾„æ—¶å‡ºé”™: {e}")

    # å‘é€å¹³å‡æŒ‡æ ‡
    for metric in metrics:
        valid_values = [results[metric] for eps, results in eps_results.items() if results[metric] is not None]
        if valid_values:
            avg = sum(valid_values) / len(valid_values)
            print(f"Average {metric} across all eps: {avg:.4f}")
            ResultSender.send_result(f"{metric}_avg", f"{avg:.4f}")
        else:
            print(f"No valid values for {metric} across all eps")
            ResultSender.send_result(f"{metric}_avg", "None")

    return eps_results, avg  # ä¿®æ­£è¿”å›å€¼ï¼ˆåŸavg_resultsæœªå®šä¹‰ï¼Œç›´æ¥è¿”å›avgï¼‰

def evaluate_clean(test_loader, estimator):
    total_incorrect_clean = 0  # ä¿®æ­£å˜é‡åï¼ˆåŸtotal_correct_cleanè¯­ä¹‰çŸ›ç›¾ï¼‰
    total_samples = 0

    for x_batch, y_batch in test_loader:
        x_batch_np = x_batch.numpy().astype(np.float32)
        y_batch_np = y_batch.numpy()
        bs = y_batch_np.shape[0]

        # åŸå§‹é¢„æµ‹
        pred_clean = process_predictions(x_batch_np, estimator)
        pred_clean_probs = softmax(pred_clean)
        # ç»Ÿè®¡é¢„æµ‹é”™è¯¯çš„æ ·æœ¬æ•°ï¼ˆåŸé€»è¾‘æ­£ç¡®ï¼Œä¿®æ­£å˜é‡åä½¿å…¶è¯­ä¹‰æ¸…æ™°ï¼‰
        total_incorrect_clean += np.sum(np.argmax(pred_clean_probs, axis=1) != y_batch_np)
        total_samples += bs

    err_clean = 100 * total_incorrect_clean / total_samples
    print(f"asr_clean (full test set): {err_clean:.2f}%")
    return err_clean

def get_original_image(images, idx, is_gray=False):
    """
    ä»4ç»´æˆ–5ç»´å¼ é‡ä¸­æå–åŸå§‹å›¾åƒï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
    å›ºå®šå–ç¬¬ä¸€ä¸ªè£å‰ªå›¾ï¼ˆcrop_idx=0ï¼‰
    Args:
        images: è¾“å…¥å¼ é‡ï¼ˆ4D: [bs, c, h, w] æˆ– 5D: [bs, ncrops, c, h, w]ï¼‰
        idx: æ ·æœ¬ç´¢å¼•
        is_gray: æ˜¯å¦ä¸ºç°åº¦å›¾åƒï¼ˆä¸‰é€šé“æ•°å€¼ä¸€è‡´ï¼‰
    Returns:
        åŸå§‹å›¾åƒï¼ˆHWCæ ¼å¼ï¼Œ0-255 uint8ï¼‰
    """
    if len(images.shape) == 5:
        # 5ç»´æ•°æ®ï¼š[bs, ncrops, c, h, w] â†’ å›ºå®šå–ç¬¬ä¸€ä¸ªè£å‰ªå—ï¼ˆcrop_idx=0ï¼‰
        img = images[idx, 0]  # [c, h, w]
    else:
        # 4ç»´æ•°æ®ï¼š[bs, c, h, w]
        img = images[idx]  # [c, h, w]
    
    # è½¬HWCæ ¼å¼
    img = img.permute(1, 2, 0).numpy()  # [h, w, c]
    
    # 0-255å½’ä¸€åŒ–
    img = (img - img.min()) / (img.max() - img.min()) * 255  # ç¡®ä¿å€¼åŸŸæ­£ç¡®æ˜ å°„
    img = img.astype(np.uint8)
    
    # ç°åº¦å›¾åƒï¼ˆä¸‰é€šé“æ•°å€¼ä¸€è‡´ï¼‰è½¬å•é€šé“
    if is_gray and img.shape[-1] == 3:
        img = img[..., 0]  # å–ä»»æ„ä¸€ä¸ªé€šé“å³å¯ï¼ˆä¸‰é€šé“æ•°å€¼ä¸€è‡´ï¼‰
    
    return img

def check_gray_image(img_tensor, tolerance=1e-3):
    """
    æ£€æŸ¥å›¾åƒæ˜¯å¦ä¸ºç°åº¦å›¾ï¼ˆé€šè¿‡åˆ¤æ–­ä¸‰é€šé“æ•°å€¼æ˜¯å¦ç›¸ä¼¼ï¼‰
    å…¼å®¹ï¼š1é€šé“ç°åº¦å›¾ã€3é€šé“ç°åº¦å›¾ï¼ˆä¸‰é€šé“æ•°å€¼ä¸€è‡´ï¼‰
    Args:
        img_tensor: å•å¼ å›¾åƒå¼ é‡ï¼ˆCHWæ ¼å¼: [c, h, w]ï¼‰
        tolerance: æ•°å€¼ç›¸ä¼¼åº¦å®¹å·®ï¼ˆé»˜è®¤1e-3ï¼Œå¯è°ƒæ•´ï¼‰
    Returns:
        bool: æ˜¯å¦ä¸ºç°åº¦å›¾åƒ
    """
    c = img_tensor.shape[0]
    if c == 1:
        # 1é€šé“ç›´æ¥åˆ¤å®šä¸ºç°åº¦å›¾
        return True
    elif c == 3:
        # 3é€šé“ï¼šåˆ¤æ–­ä¸‰ä¸ªé€šé“çš„æ•°å€¼æ˜¯å¦åœ¨å®¹å·®èŒƒå›´å†…ä¸€è‡´
        channel1 = img_tensor[0].cpu().numpy()
        channel2 = img_tensor[1].cpu().numpy()
        channel3 = img_tensor[2].cpu().numpy()
        
        # è®¡ç®—é€šé“é—´çš„æœ€å¤§å·®å¼‚
        max_diff12 = np.max(np.abs(channel1 - channel2))
        max_diff13 = np.max(np.abs(channel1 - channel3))
        
        return max_diff12 < tolerance and max_diff13 < tolerance
    else:
        # å…¶ä»–é€šé“æ•°æš‚ä¸æ”¯æŒï¼Œé»˜è®¤åˆ¤å®šä¸ºå½©è‰²å›¾
        return False

def apply_corruption_to_crop(crop_img, corruption_func, severity, is_gray):
    """
    å¯¹å•ä¸ªè£å‰ªå—åº”ç”¨æ‰°åŠ¨ï¼ˆä¿æŒç°åº¦/å½©è‰²ä¸€è‡´æ€§ï¼‰
    Args:
        crop_img: å•ä¸ªè£å‰ªå—å¼ é‡ [c, h, w]ï¼ˆCHWæ ¼å¼ï¼‰
        corruption_func: æ‰°åŠ¨å‡½æ•°
        severity: æ‰°åŠ¨å¼ºåº¦
        is_gray: æ˜¯å¦ä¸ºç°åº¦å›¾åƒï¼ˆä¸‰é€šé“æ•°å€¼ä¸€è‡´ï¼‰
    Returns:
        æ‰°åŠ¨åçš„è£å‰ªå—å¼ é‡ [c, h, w]ï¼ˆCHWæ ¼å¼ï¼‰
    """
    # è½¬HWCæ ¼å¼å¹¶å½’ä¸€åŒ–åˆ°0-255 uint8
    crop_hwc = crop_img.permute(1, 2, 0).numpy()  # [h, w, c]
    crop_hwc = (crop_hwc - crop_hwc.min()) / (crop_hwc.max() - crop_hwc.min()) * 255
    crop_hwc = crop_hwc.astype(np.uint8)
    
    # ç°åº¦å›¾åƒå¤„ç†ï¼ˆè½¬ä¸ºå•é€šé“é¿å…æ‰°åŠ¨å‡½æ•°ç”Ÿæˆå½©è‰²ï¼‰
    if is_gray:
        if crop_hwc.shape[-1] == 3:
            # 3é€šé“ç°åº¦å›¾ â†’ å•é€šé“
            crop_hwc = crop_hwc[..., 0]  # å–ç¬¬ä¸€ä¸ªé€šé“ï¼ˆä¸‰é€šé“æ•°å€¼ä¸€è‡´ï¼‰
    
    # åº”ç”¨æ‰°åŠ¨
    corrupted_hwc = corruption_func(crop_hwc, severity=severity)
    
    # æ¢å¤é€šé“æ•°ï¼ˆç°åº¦â†’ä¿æŒå•é€šé“æˆ–è½¬ä¸º3é€šé“ï¼Œå½©è‰²ä¿æŒ3é€šé“ï¼‰
    if is_gray:
        if corrupted_hwc.ndim == 2:
            # å•é€šé“ â†’ æ¢å¤ä¸ºåŸå§‹é€šé“æ•°ï¼ˆ1æˆ–3ï¼‰
            if crop_img.shape[0] == 1:
                corrupted_hwc = np.expand_dims(corrupted_hwc, axis=-1)  # [h, w, 1]
            else:  # åŸå§‹ä¸º3é€šé“ç°åº¦å›¾
                corrupted_hwc = np.repeat(np.expand_dims(corrupted_hwc, axis=-1), 3, axis=-1)  # [h, w, 3]
        elif corrupted_hwc.ndim == 3 and corrupted_hwc.shape[-1] == 3:
            # éƒ¨åˆ†æ‰°åŠ¨å‡½æ•°å¯èƒ½è¾“å‡º3é€šé“ï¼Œè½¬ç°åº¦ï¼ˆå–å‡å€¼æˆ–ä»»æ„é€šé“ï¼‰
            corrupted_hwc = np.expand_dims(np.mean(corrupted_hwc, axis=-1), axis=-1).astype(np.uint8)
            if crop_img.shape[0] == 3:
                corrupted_hwc = np.repeat(corrupted_hwc, 3, axis=-1)  # æ¢å¤3é€šé“
    
    # å½’ä¸€åŒ–åˆ°0-1å¹¶è½¬CHWæ ¼å¼
    corrupted_chw = torch.from_numpy(corrupted_hwc / 255.0).permute(2, 0, 1).float()
    
    return corrupted_chw

def evaluate_robustness_corruptions(test_loader, estimator, metrics):
    ResultSender.send_log("è¿›åº¦", "æ‰°åŠ¨æ”»å‡»è¯„æµ‹å¼€å§‹")
    # å®šä¹‰æ‰°åŠ¨æ–¹æ³•ï¼ˆå¯æ ¹æ®éœ€è¦è§£é™¤æ³¨é‡Šæ‰©å±•ï¼‰
    corruption_functions = [
        gaussian_noise,
        # shot_noise, impulse_noise, speckle_noise,
        # gaussian_blur, glass_blur, defocus_blur, motion_blur, zoom_blur,
        # fog, frost, snow, spatter, contrast, brightness, saturate,
        # jpeg_compression, pixelate, elastic_transform
    ]
    severity_levels = [1, 2, 3, 4, 5]
    asr_total = 0
    selected_severity_for_saving = [1, 2] if len(severity_levels) > 1 else [severity_levels[0]]

    for corruption_function in corruption_functions:
        corruption_name = corruption_function.__name__
        for severity in severity_levels:
            total_samples = 0
            incorrect_count = 0
            save_dir = None
            should_save_images = severity in selected_severity_for_saving

            # åˆ›å»ºä¿å­˜ç›®å½•
            if should_save_images:
                evaluateMetric = os.getenv("evaluateDimension")
                if evaluateMetric:
                    save_dir = os.path.join("..", "evaluationData", evaluateMetric, "output")
                    os.makedirs(save_dir, exist_ok=True)
                else:
                    save_dir = f"corruption_examples_{corruption_function.__name__}_{severity}"
                    os.makedirs(save_dir, exist_ok=True)

            saved_images_count = 0
            max_saved_images = 5

            with torch.no_grad():
                for data in test_loader:
                    images, labels = data
                    bs = images.shape[0]  # æ— è®º4ç»´è¿˜æ˜¯5ç»´ï¼Œæ‰¹æ¬¡å¤§å°éƒ½æ˜¯ç¬¬ä¸€ç»´

                    for i in range(bs):
                        true_label = labels[i].item()
                        original_input = images[i:i+1].numpy()  # åŸå§‹è¾“å…¥ï¼ˆä¿æŒ4D/5Dæ ¼å¼ï¼‰
                        pred_clean = process_predictions(original_input, estimator)
                        clean_pred_label = np.argmax(pred_clean, axis=1)[0]

                        # æ£€æµ‹å½“å‰æ ·æœ¬æ˜¯å¦ä¸ºç°åº¦å›¾ï¼ˆå–ç¬¬ä¸€ä¸ªè£å‰ªå—è¿›è¡Œæ£€æµ‹ï¼‰
                        if len(images.shape) == 5:
                            sample_img = images[i, 0]  # [c, h, w]ï¼ˆç¬¬ä¸€ä¸ªè£å‰ªå—ï¼‰
                        else:
                            sample_img = images[i]  # [c, h, w]
                        is_gray = check_gray_image(sample_img)

                        # ç”Ÿæˆæ‰°åŠ¨è¾“å…¥ï¼ˆå…³é”®ä¿®å¤ï¼šå¤ç”¨åŸå§‹è£å‰ªå—ï¼Œå›ºå®šå–ç¬¬ä¸€ä¸ªè£å‰ªå›¾ç”¨äºæ‰°åŠ¨ï¼‰
                        if len(images.shape) == 5:
                            # 5Dæ•°æ®ï¼š[bs, ncrops, c, h, w] â†’ å¯¹æ¯ä¸ªè£å‰ªå—å•ç‹¬æ‰°åŠ¨ï¼ˆä¿æŒè£å‰ªä½ç½®ä¸€è‡´ï¼‰
                            ncrops = images.shape[1]
                            corrupted_crops = []
                            for crop_idx in range(ncrops):
                                # æå–å•ä¸ªè£å‰ªå—
                                crop_img = images[i, crop_idx]  # [c, h, w]
                                # åº”ç”¨æ‰°åŠ¨ï¼ˆä¿æŒç°åº¦/å½©è‰²ä¸€è‡´æ€§ï¼‰
                                corrupted_crop = apply_corruption_to_crop(
                                    crop_img, corruption_function, severity, is_gray
                                )
                                corrupted_crops.append(corrupted_crop)
                            # é‡ç»„ä¸º5Då¼ é‡ï¼š[1, ncrops, c, h, w]
                            corrupted_tensor = torch.stack(corrupted_crops).unsqueeze(0)
                        else:
                            # 4Dæ•°æ®ï¼š[bs, c, h, w] â†’ ç›´æ¥æ‰°åŠ¨
                            img = images[i]  # [c, h, w]
                            corrupted_tensor = apply_corruption_to_crop(
                                img, corruption_function, severity, is_gray
                            ).unsqueeze(0)  # [1, c, h, w]

                        # è½¬numpyæ ¼å¼ç”¨äºé¢„æµ‹
                        model_input = corrupted_tensor.numpy()
                        pred = process_predictions(model_input, estimator)
                        pred_label = np.argmax(pred, axis=1)[0]

                        # ç»Ÿè®¡é”™è¯¯æ•°
                        if pred_label != true_label:
                            incorrect_count += 1
                        total_samples += 1

                        # ä¿å­˜å¯¹æ¯”å›¾åƒï¼ˆä»…å½“åŸå§‹é¢„æµ‹æ­£ç¡®ä¸”æ‰°åŠ¨åé¢„æµ‹é”™è¯¯æ—¶ï¼‰
                        if should_save_images and saved_images_count < max_saved_images:
                            if clean_pred_label == true_label and pred_label != true_label:
                                # æå–å¯è§†åŒ–ç”¨çš„åŸå§‹å›¾åƒå’Œæ‰°åŠ¨å›¾åƒï¼ˆå‡å–ç¬¬ä¸€ä¸ªè£å‰ªå—ï¼‰
                                clean_img_vis = get_original_image(images, i, is_gray)
                                # æ‰°åŠ¨å›¾åƒå–ç¬¬ä¸€ä¸ªè£å‰ªå—
                                if len(corrupted_tensor.shape) == 5:
                                    corrupted_img_vis = corrupted_tensor[0, 0].permute(1, 2, 0).numpy()
                                else:
                                    corrupted_img_vis = corrupted_tensor[0].permute(1, 2, 0).numpy()
                                # è½¬0-255 uint8
                                corrupted_img_vis = (corrupted_img_vis * 255).astype(np.uint8)
                                # ç°åº¦å›¾åƒå¤„ç†ï¼ˆä¸‰é€šé“â†’å•é€šé“ï¼‰
                                if is_gray and corrupted_img_vis.ndim == 3 and corrupted_img_vis.shape[-1] == 3:
                                    corrupted_img_vis = corrupted_img_vis[..., 0]

                                save_corruption_comparison(
                                    clean_img_vis,
                                    corrupted_img_vis,
                                    true_label,
                                    clean_pred_label,
                                    pred_label,
                                    saved_images_count,
                                    save_dir,
                                    corruption_name,
                                    severity
                                )
                                saved_images_count += 1

            # è®¡ç®—ASRï¼ˆæ”»å‡»æˆåŠŸç‡=é”™è¯¯æ•°/æ€»æ ·æœ¬æ•°ï¼‰
            if total_samples > 0:
                asr = 100 * incorrect_count / total_samples
                asr_total += asr
                # æ—¥å¿—è¾“å‡º
                ResultSender.send_log("è¿›åº¦",
                                      f"UnCorrectNum of {corruption_name}_severity_{severity}: {incorrect_count}")
                ResultSender.send_log("è¿›åº¦",
                                      f"ASR of {corruption_name}_severity_{severity}: {asr:.2f}%")
                print(f"UnCorrectNum of {corruption_name}_severity_{severity}: {incorrect_count}")
                print(f"ASR of {corruption_name}_severity_{severity}: {asr:.2f}%")
                
                # å›¾åƒä¿å­˜æ—¥å¿—
                if should_save_images:
                    if saved_images_count > 0:
                        print(f"å·²ä¿å­˜ {saved_images_count} ç»„ {corruption_name}_severity_{severity} å¯¹æ¯”å›¾åˆ° {save_dir}")
                    else:
                        print(f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ ·æœ¬ï¼ˆåŸå§‹é¢„æµ‹æ­£ç¡®+æ‰°åŠ¨é¢„æµ‹é”™è¯¯ï¼‰ï¼Œæœªä¿å­˜ {corruption_name}_severity_{severity} å¯¹æ¯”å›¾")
            else:
                print(f"è­¦å‘Šï¼š{corruption_name}_severity_{severity} æœªå¤„ç†ä»»ä½•æ ·æœ¬")

        # å‘é€é€‰å®šseverityçº§åˆ«çš„å¯¹æ¯”å›¾è·¯å¾„
        try:
            # è·å–ç¯å¢ƒå˜é‡
            evaluateMetric = os.getenv("evaluateDimension")
            resultPath = os.getenv("resultPath")

            if evaluateMetric and resultPath and selected_severity_for_saving:
                for severity in selected_severity_for_saving:
                    # ç›´æ¥åœ¨ç»“æœç›®å½•ä¸­æŸ¥æ‰¾å›¾åƒ
                    target_dir_rel = os.path.join("..", "evaluationData", evaluateMetric, "output")
                    target_dir_abs = os.path.join(resultPath, evaluateMetric, "output")

                    # æ£€æŸ¥å›¾åƒæ˜¯å¦å­˜åœ¨
                    target_img_name = f"{corruption_function.__name__}_severity_{severity}_comparison_0.png"
                    target_img_path_rel = os.path.join(target_dir_rel, target_img_name)
                    target_img_path_abs = os.path.join(target_dir_abs, target_img_name)

                    print(f"æ£€æŸ¥æ‰°åŠ¨æ”»å‡»å›¾ç‰‡è·¯å¾„: {target_img_path_rel}")
                    print(f"æ£€æŸ¥æ‰°åŠ¨æ”»å‡»å›¾ç‰‡ç»å¯¹è·¯å¾„: {target_img_path_abs}")

                    if os.path.exists(target_img_path_rel):
                        # é€šè¿‡ResultSenderå‘é€è·¯å¾„
                        ResultSender.send_result(
                            f"{corruption_function.__name__}_severity_{severity}_comparison_0_path",
                            target_img_path_abs)

                        # æ‰“å°ä¿å­˜è·¯å¾„
                        print(f"æ‰°åŠ¨æ”»å‡»å¯¹æ¯”å›¾å·²ä¿å­˜: {target_img_path_abs}")
                    else:
                        print(f"æ‰°åŠ¨æ”»å‡»å¯¹æ¯”å›¾ä¸å­˜åœ¨: {target_img_path_rel}")
            else:
                print("ç¯å¢ƒå˜é‡ evaluateDimension æˆ– resultPath æœªè®¾ç½®ï¼Œè·³è¿‡å‘é€å¯¹æ¯”å›¾è·¯å¾„")
        except Exception as e:
            print(f"å‘é€æ‰°åŠ¨æ”»å‡»å¯¹æ¯”å›¾è·¯å¾„æ—¶å‡ºé”™: {e}")

    # è®¡ç®—mCEï¼ˆå¹³å‡ corruption errorï¼‰
    num_corruptions = len(corruption_functions)
    num_severities = len(severity_levels)
    if num_corruptions > 0 and num_severities > 0:
        mCE = asr_total / (num_corruptions * num_severities)
        print(f"mCE (Average Corruption Error): {mCE:.2f}%")
        if "mCE" in metrics:
            ResultSender.send_result("mCE", f"{mCE / 100:.4f}")  # è½¬æ¢ä¸ºå°æ•°å½¢å¼

        # è®¡ç®—RmCEï¼ˆç›¸å¯¹ mCE = mCE - å¹²å‡€æ ·æœ¬é”™è¯¯ç‡ï¼‰
        if "RmCE" in metrics:
            err_clean = evaluate_clean(test_loader, estimator)
            RmCE = mCE - err_clean
            print(f"RmCE (Relative mCE): {RmCE:.2f}%")
            ResultSender.send_result("RmCE", f"{RmCE / 100:.4f}")  # è½¬æ¢ä¸ºå°æ•°å½¢å¼
    else:
        print("è­¦å‘Šï¼šæœªè®¡ç®—mCEï¼ˆæ— æ‰°åŠ¨æ–¹æ³•æˆ–severityçº§åˆ«ï¼‰")
        if "mCE" in metrics:
            ResultSender.send_result("mCE", "0.0000")
        if "RmCE" in metrics:
            ResultSender.send_result("RmCE", "0.0000")